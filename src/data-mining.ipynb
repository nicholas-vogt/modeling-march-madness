{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining\n",
    "\n",
    "Disclaimer: The following code was written in Python 3.5.2\n",
    "\n",
    "We're going to mine [gamesheets from sports-reference.com](http://www.sports-reference.com/cbb/boxscores/index.cgi?month=02&day=3&year=2017). Note that all we collect are the name of the winning and losing teams, and their scores. Nothing more. \n",
    "\n",
    "Data mining scripts involve many lines of code depending on the source html. This sports-reference data requires relatively short scripts. Since this is a tutorial, you _won't_ be fully comfortable understanding each line of code. Focus instead on the whole process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load raw html and make soup\n",
    "\n",
    "I've already downloaded the source html for games played on February 3, 2017. Open [this link](http://www.sports-reference.com/cbb/boxscores/index.cgi?month=02&day=3&year=2017) and follow along!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "with open('./../html/sample-gamesheets/2017-2-3.txt', 'rb') as raw_html:\n",
    "    soup = BeautifulSoup(raw_html.read().decode(), 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect team names and scores\n",
    "\n",
    "This is where the [SelectorGadget](http://selectorgadget.com/) becomes a time-saver. Every argument to the `find` and `find_all` functions comes directly from the SelectorGadget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffalo  96 69  Ball State\n"
     ]
    }
   ],
   "source": [
    "# BeautifulSoup has keyword arguments which correspond to attribute keywords.\n",
    "# Here I use a keyword argument (class_ = \"game_summaries\")\n",
    "# and a dictionary for attribute keywords ({\"class\": \"game_summary nohover\"})\n",
    "game_summary = soup.find(class_=\"game_summaries\") \\\n",
    "                   .find('div', {\"class\": \"game_summary nohover\"})\n",
    "\n",
    "winner_data = game_summary.find(class_='winner')\n",
    "winning_team = winner_data.a.text.strip()\n",
    "winning_score = winner_data.find(class_='right').text.strip()\n",
    "\n",
    "loser_data = game_summary.find(class_='loser')\n",
    "losing_team = loser_data.a.text.strip()\n",
    "losing_score = loser_data.find(class_='right').text.strip()\n",
    "\n",
    "print(\"{}  {} {}  {}\".format(winning_team, winning_score, losing_score, losing_team))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffalo                     96   69                Ball State\n",
      "Central Michigan            86   82          Western Michigan\n",
      "Yale                        87   78                  Columbia\n",
      "Brown                       81   70                   Cornell\n",
      "Princeton                   69   64                 Dartmouth\n",
      "Rhode Island                70   59                  Davidson\n",
      "Harvard                     69   59                      Penn\n",
      "Monmouth                    71   70               St. Peter's\n",
      "Iona                        95   76                     Rider\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "Team = namedtuple('Team', ('name', 'points', 'won'))\n",
    "\n",
    "def get_game_summaries(soup):\n",
    "    \"\"\"Get ResultSet of game summaries from soup object.\n",
    "    \n",
    "    Arguments:\n",
    "        soup (BeautifulSoup) -- Contains game summary data.\n",
    "        \n",
    "    Returns: ResultSet of game summaries.\n",
    "    \"\"\"\n",
    "    game_summaries = soup.find(class_=\"game_summaries\") \\\n",
    "                         .find_all('div', {\"class\":'game_summary nohover'})\n",
    "    return game_summaries\n",
    "\n",
    "def get_game_data(game_summary):\n",
    "    \"\"\"Mine game summary data from game summary.\n",
    "    \n",
    "    Arguments:\n",
    "        game_summary (str) -- Contains teams and scores.\n",
    "    \n",
    "    Returns: Tuple of (winning_team, winning_score, losing_team, losing_score)\n",
    "    \"\"\"\n",
    "    team_data = game_summary.find(class_='winner')\n",
    "    if not team_data:  # sometimes returns a NoneType\n",
    "        raise Exception(\"No data was found.\")\n",
    "    winning_team = team_data.a.text.strip()\n",
    "    winning_score = team_data.find(class_='right').text.strip()\n",
    "\n",
    "    team_data = game_summary.find(class_='loser')\n",
    "    losing_team = team_data.a.text.strip()\n",
    "    losing_score = team_data.find(class_='right').text.strip()\n",
    "\n",
    "    return (winning_team, winning_score, losing_team, losing_score)\n",
    "\n",
    "for game_summary in get_game_summaries(soup):\n",
    "    winning_team, winning_score, losing_team, losing_score = get_game_data(game_summary)\n",
    "    print(\"{:<25} {:>4} {:>4} {:>25}\".format(winning_team, winning_score, losing_score, losing_team))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're missing the date. That seems like valuable information we should hold onto.\n",
    "\n",
    "### Method 1\n",
    "Write a function to grab the date from each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Feb', '3', '2017')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_date(soup):\n",
    "    \"\"\"\n",
    "    Collects date from html.\n",
    "    \"\"\"\n",
    "    raw = soup.find(class_=\"game_summaries\").h2.text.strip()\n",
    "    scores, date = raw.split('â€”')\n",
    "    month, day, year = date.strip().replace(',', '').split(' ')\n",
    "    return month, day, year\n",
    "get_date(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're about to do something difficult, remember: \n",
    "\n",
    "## DON'T\n",
    "\n",
    "**D**emands: Does my project require this?  \n",
    "**O**nline sources: Has someone else done it better?  \n",
    "**N**etwork: Are my friends smarter than me?  \n",
    "**T**ry something else.\n",
    "\n",
    "### Method 2\n",
    "\n",
    "When scraping the original data, we used the date as our unique identifier to tell files apart. We can just borrow the date from our file path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-2-3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path as ospath\n",
    "\n",
    "def get_date(fp):\n",
    "    \"\"\"Returns date from file path argument.\"\"\"\n",
    "    parent, child = ospath.split(fp)  # returns ('./../html/sample-gamesheets', '2017-2-3.txt')\n",
    "    date = child.replace('.txt', '')  # returns '2017-2-3'\n",
    "    return date\n",
    "\n",
    "file_path = './../html/sample-gamesheets/2017-2-3.txt'\n",
    "get_date(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Pull It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-2-3   Buffalo                     96   69                Ball State\n",
      "2017-2-3   Central Michigan            86   82          Western Michigan\n",
      "2017-2-3   Yale                        87   78                  Columbia\n",
      "2017-2-3   Brown                       81   70                   Cornell\n",
      "2017-2-3   Princeton                   69   64                 Dartmouth\n",
      "2017-2-3   Rhode Island                70   59                  Davidson\n",
      "2017-2-3   Harvard                     69   59                      Penn\n",
      "2017-2-3   Monmouth                    71   70               St. Peter's\n",
      "2017-2-3   Iona                        95   76                     Rider\n"
     ]
    }
   ],
   "source": [
    "file_path = './../html/sample-gamesheets/2017-2-3.txt'\n",
    "date = get_date(file_path)\n",
    "for game_summary in get_game_summaries(soup):\n",
    "    winning_team, winning_score, losing_team, losing_score = get_game_data(game_summary)\n",
    "    print(\"{:<10} {:<25} {:>4} {:>4} {:>25}\".format(date, winning_team, winning_score, losing_score, losing_team))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Writing Data\n",
    "\n",
    "Writing data may be the easiest part of the process. The hard part is doing it _quickly_. There are a number of ways we can do this, but I'll show you one way that I like best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_writer(data_path, colnames):\n",
    "    \"\"\"Initialize writer.\n",
    "    \n",
    "    Arguments:\n",
    "        data_path (str) -- Relative or absolute path to exported data.\n",
    "        colnames (tuple, List) -- Column names to be exported with data.\n",
    "        \n",
    "    Returns: io Buffered Writer to tab-separated variable file.\n",
    "    \"\"\"\n",
    "    writer = open(data_path, 'wb')\n",
    "    header = \"\\t\".join(colnames) + '\\n'\n",
    "    writer.write(header.encode('utf-8'))\n",
    "    return writer\n",
    "\n",
    "data_path = \"./../data/sample-gamesheets.txt\"\n",
    "colnames = (\"Date\", \"WinningTeam\", \"WinningScore\", \"LosingTeam\", \"LosingScore\")\n",
    "writer = init_writer(data_path, colnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here you can write rows as necessary without ever closing the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html_path = './../html/sample-gamesheets/2017-2-3.txt'\n",
    "date = get_date(html_path)\n",
    "\n",
    "data_path = \"./../data/sample-gamesheets.txt\"\n",
    "colnames = (\"Date\", \"WinningTeam\", \"WinningScore\", \"LosingTeam\", \"LosingScore\")\n",
    "writer = init_writer(data_path, colnames)\n",
    "\n",
    "for game_summary in get_game_summaries(soup):    \n",
    "    row = \"\\t\".join([date] + list(get_game_data(game_summary))) + '\\n'\n",
    "    writer.write(row.encode())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's quick look at our data file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'WinningTeam', 'WinningScore', 'LosingTeam', 'LosingScore\\n']\n",
      "['2017-2-3', 'Buffalo', '96', 'Ball State', '69\\n']\n",
      "['2017-2-3', 'Central Michigan', '86', 'Western Michigan', '82\\n']\n",
      "['2017-2-3', 'Yale', '87', 'Columbia', '78\\n']\n",
      "['2017-2-3', 'Brown', '81', 'Cornell', '70\\n']\n",
      "['2017-2-3', 'Princeton', '69', 'Dartmouth', '64\\n']\n",
      "['2017-2-3', 'Rhode Island', '70', 'Davidson', '59\\n']\n",
      "['2017-2-3', 'Harvard', '69', 'Penn', '59\\n']\n",
      "['2017-2-3', 'Monmouth', '71', \"St. Peter's\", '70\\n']\n",
      "['2017-2-3', 'Iona', '95', 'Rider', '76\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(data_path, 'rb') as ifile:\n",
    "    for line in ifile:\n",
    "        print(line.decode().split('\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can examine the data file in Excel by importing the text file. I prefer this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miner Class\n",
    "\n",
    "We need to use Python classes to mine efficiently. The following Python files in the /src directory will be helpful: \n",
    "\n",
    "- Miner.py: Base Miner Class\n",
    "- BoxscoreMiner.py: Mines Box Score Data\n",
    "- GamesheetMiner.py: Mines Gamesheet Data\n",
    "\n",
    "If you're reading this later, there are several articles online which explain inheritance better than I can. Once you've covered that, go over and look at the Miner classes listed above. Most of the \n",
    "\n",
    "### Base Miner Class\n",
    "\n",
    "This exists because some functions are common to each Miner. If, heaven forbid, we need to update one of these functions, we want to change it in one place, and _only_ one place. \n",
    "\n",
    "### Gamesheet Miner\n",
    "\n",
    "The `GamesheetMiner` will pull everything together that we've done so far. When we're done, the following code will mine and export all the gamesheet data.\n",
    "\n",
    "```\n",
    "miner = GamesheetMiner(\"./../data/feb-gamesheets.txt\")\n",
    "gamesheet_dir = \"./../html/sample-gamesheets/\"\n",
    "for root, dirs, files in os.walk(gamesheet_dir):\n",
    "    for f in files:\n",
    "        if f.endswith('txt'):\n",
    "            print(\"Mining\", f)\n",
    "            miner.mine_gamesheet(os.path.join(gamesheet_dir, f))\n",
    "            miner.write()\n",
    "```\n",
    "\n",
    "### Boxscore Miner\n",
    "\n",
    "Because scores alone aren't very interesting, I've gone ahead and made a `BoxscoreMiner` class to get some more interesting data. In the end, the following code will mine and export all boxscore data.\n",
    "\n",
    "```\n",
    "miner = BoxscoreMiner(\"./../data/feb-boxscores.txt\")\n",
    "boxscore_dir = \"./../html/sample-boxscores/\"\n",
    "for root, dirs, files in os.walk(boxscore_dir):\n",
    "    for f in files:\n",
    "        if f.endswith('txt'):\n",
    "            print(\"Mining\", f)\n",
    "            miner.mine_boxscore(os.path.join(boxscore_dir, f))\n",
    "            miner.write()\n",
    "```\n",
    "\n",
    "See how similar the different programs are? This is why we use classes. **It's easier to remember how to use each class when they have the same interface**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
